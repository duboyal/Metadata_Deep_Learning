{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE VS METADATA:\n",
    "This notebook trains a baseline model and then peforms the same training techniques on upsampled training data (upsampled based of off metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import PIL # Python imaging library, support for opening, manipulating, saving different image file formats\n",
    "\n",
    "from utils import LSUNDataloader # import our defined dataloader\n",
    "from collections import OrderedDict\n",
    "import itertools \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the below cell sets our architecture to resnet18 and \"param.requires_grad = False\" freezes all our layers besides this custom head defined as fc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arch = models.resnet18(pretrained=True) #models class has resnet\n",
    "for param in arch.parameters():\n",
    "    param.requires_grad = False \n",
    "    \n",
    "fc  = nn.Sequential(OrderedDict([\n",
    "                                ('fc1',nn.Linear(512,100,bias=True)),\n",
    "                                ('batchnorm',nn.BatchNorm1d(100,eps=1e-05,momentum=0.1,affine=True)),\n",
    "                                ('relu',nn.ReLU()),\n",
    "                                ('dropout',nn.Dropout(p=0.25)),\n",
    "                                ('fc2',nn.Linear(100,10,bias=True)),\n",
    "                                ('output',nn.LogSoftmax())\n",
    "                                ]))\n",
    "arch.fc = fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below we are setting our training device to cuda gpu if it exists, else using the cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "arch_meta = copy.deepcopy(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arch = arch.to(device)\n",
    "arch_meta = arch_meta.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"/home/DATASETS/LSUN/data\"\n",
    "train_path = f'{PATH}/train'\n",
    "val_path = f'{PATH}/valid'\n",
    "train_data = pd.read_csv(f'{PATH}/train.csv',index_col=False)\n",
    "val_data = pd.read_csv(f'{PATH}/valid.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we define our transformations for both train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    'train' : transforms.Compose([\n",
    "        #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.25),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        transforms.Resize((224,224)),\n",
    "        #transforms.RandomRotation(degrees=[0,270]),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val' : transforms.Compose([\n",
    "        #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.25),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        transforms.Resize((224,224)),\n",
    "        #transforms.RandomRotation(degrees=[0,270]),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our dataloader, see LSUNDataloader.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = LSUNDataloader.LSUNDataset(PATH,\"train\",transformations['train'])\n",
    "val_dataset = LSUNDataloader.LSUNDataset(PATH,\"valid\",transformations['val'])\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset= val_dataset, batch_size=32, shuffle=True)\n",
    "dataloader = {\n",
    "    'train':train_dataloader, 'val':val_dataloader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train':len(train_dataset), 'val': len(val_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below we set our loss function with criterion, loads architecture parameters and learning rate with adam optimizer. lr_scheduler.StepLR changes the learning rate after certain step size amount of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(arch.parameters(),lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer,step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is our train_model function which was stronogly modeled after this tutorial https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in tqdm_notebook(dataloader[phase]):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #labels = labels.long()\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "calling train model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da1de8cd1db4367921fb52c4c313a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 1.8712 Acc: 0.4860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fe8d50bd024ebbb1031ae323b118f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 1.5109 Acc: 0.6980\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df943150f1c4e869af61d38251d50f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 1.3146 Acc: 0.7470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ec3627ae6e499fb78f48926acb3264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 1.1640 Acc: 0.7640\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d191fddb3f1e442b863c96661afd6a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.9929 Acc: 0.7890\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079a374171f84a078ae7c7bf018084e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.9481 Acc: 0.7620\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367cd1a1cafa4ae5a6ca8146ecaea173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.7800 Acc: 0.8150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f82d9fb317d440d9d7a6d7e82479692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.8192 Acc: 0.7780\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f9fb58b77a4e9a8055a62c9b26464d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.6404 Acc: 0.8510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd6b7c24c02452483034598b92b1728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.7665 Acc: 0.7760\n",
      "\n",
      "Training complete in 0m 38s\n",
      "Best val Acc: 0.778000\n"
     ]
    }
   ],
   "source": [
    "arch = train_model(arch,criterion=criterion,optimizer=optimizer,scheduler=exp_lr_scheduler,num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{PATH}/test.csv\",index_col=False)\n",
    "    #below loading test path using val transformations\n",
    "test_dataset = LSUNDataloader.LSUNDataset(PATH,\"test\",transformations['val']) \n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filling in the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab7cf01fd9147a69035f496bd2ac009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "yhat = []\n",
    "lab = []\n",
    "misclassified = []\n",
    "arch = arch.eval()\n",
    "with torch.no_grad(): # (while not training, but while testing)\n",
    "    for data in tqdm_notebook(test_dataloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = arch(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        for i in predicted.to(\"cpu\").numpy():\n",
    "            yhat.append(i) # predictions: confidence\n",
    "        for j in labels.to(\"cpu\").numpy():\n",
    "            lab.append(j) # predictions: label\n",
    "        #_, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze() #predicted should match with actual labels\n",
    "        for i in range(len(c.cpu())):\n",
    "            if c[i]==0:\n",
    "                misclassified.append(images.to(\"cpu\")[i])\n",
    "            \n",
    "c1 = confusion_matrix(lab,yhat)\n",
    "c1 = c1.astype('int') / c1.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(lab,yhat,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ('bedroom','bridge','church','class','conf','dining','kitchen','living','restaurant','tower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultPATH = '/home/Alex/LSUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WriteLog(c1,name,f1,resultPATH): #c1 - confusion matrix, name- name of your experiment, f1_score\n",
    "    results = pd.read_csv(f\"{resultPATH}/Results_LSUN.csv\",index_col=False)\n",
    "    exp_log = pd.read_csv(f\"{resultPATH}/ExperimentLog.csv\",index_col=False)\n",
    "    diag = [round(c1[i][i],3) for i in range(len(c1)) ]\n",
    "    diag.append(round(f1,3))\n",
    "    diag.insert(0,len(results))\n",
    "    results.loc[len(results)] = diag\n",
    "    exp_log.loc[len(exp_log)] = [len(results)-1,name]\n",
    "    results.to_csv(f\"{resultPATH}/Results_LSUN.csv\",index=False)\n",
    "    exp_log.to_csv(f\"{resultPATH}/ExperimentLog.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WriteLog(c1,\"Baseline\",f1,resultPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Metadata Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \"Upsample_bridge\" is the name of csv we wanted to train on, specifically here we \n",
    " our last one, we trained on bridge, \n",
    "\n",
    " now we repeat the same process training process with an upsampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = LSUNDataloader.LSUNDataset(PATH,\"Upsample_bridge\",transformations['train'])\n",
    "val_dataset = LSUNDataloader.LSUNDataset(PATH,\"valid\",transformations['val'])\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset= val_dataset, batch_size=32, shuffle=True)\n",
    "dataloader = {\n",
    "    'train':train_dataloader, 'val':val_dataloader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train':len(train_dataset), 'val': len(val_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(arch_meta.parameters(),lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer,step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae61496cbe34935880bbcf5d6572df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8959 Acc: 0.4845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6035e518af4cc9aa074c8db8537ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.5313 Acc: 0.6760\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a343ef209e0a4c738ca2c690ec4509ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3607 Acc: 0.7524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88eea364a9c4843941bfedb052953de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2208 Acc: 0.7600\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0562529f3e41f6b72cfca75aed78bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0509 Acc: 0.8049\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb02c8f4c8244efb1151e8d515452f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9998 Acc: 0.7820\n",
      "\n",
      "Training complete in 0m 24s\n",
      "Best val Acc: 0.782000\n"
     ]
    }
   ],
   "source": [
    "arch_meta = train_model(arch_meta,criterion=criterion,optimizer=optimizer,scheduler=exp_lr_scheduler,num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again filling out the confusion matrix\n",
    "\n",
    "#### Note that test data is the same for original test data and metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accad5547b794b1a9897fcdea7188cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "yhat2 = []\n",
    "lab2 = []\n",
    "arch_meta = arch_meta.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm_notebook(test_dataloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = arch_meta(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        for i in predicted.to(\"cpu\").numpy():\n",
    "            yhat2.append(i)\n",
    "        for j in labels.to(\"cpu\").numpy():\n",
    "            lab2.append(j)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "c2 = confusion_matrix(lab2,yhat2)\n",
    "c2 = c2.astype('float') / c2.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2 = f1_score(lab2,yhat2,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WriteLog(c2,\"Upsample_bridge\",f2,resultPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"/home/Alex/LSUN/Results_LSUN.csv\",index_col=False)\n",
    "exp_log = pd.read_csv(\"/home/Alex/LSUN/ExperimentLog.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>bridge</th>\n",
       "      <th>church</th>\n",
       "      <th>class</th>\n",
       "      <th>conf</th>\n",
       "      <th>dining</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>living</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>tower</th>\n",
       "      <th>TotalAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number  bedroom  bridge  church  class   conf  dining  kitchen  living  \\\n",
       "0     0.0    0.660   0.936   0.891  0.731  0.583   0.689    0.945   0.542   \n",
       "1     1.0    0.809   0.894   0.826  0.808  0.667   0.667    0.945   0.407   \n",
       "2     2.0    0.894   0.830   0.826  0.788  0.583   0.711    0.927   0.288   \n",
       "3     3.0    0.681   0.957   0.935  0.712  0.812   0.733    0.945   0.610   \n",
       "4     4.0    0.830   0.851   0.913  0.731  0.646   0.689    0.909   0.542   \n",
       "5     5.0    0.766   0.872   0.957  0.731  0.646   0.711    0.873   0.458   \n",
       "\n",
       "   restaurant  tower  TotalAccuracy  \n",
       "0       0.804   0.76          0.752  \n",
       "1       0.863   0.80          0.764  \n",
       "2       0.804   0.70          0.728  \n",
       "3       0.647   0.64          0.764  \n",
       "4       0.686   0.70          0.746  \n",
       "5       0.745   0.76          0.746  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Metadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Baseline_Upsample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Upsample_living_conf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Upsample_conf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Upsample_bridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number            Experiment\n",
       "0       0              Baseline\n",
       "1       1              Metadata\n",
       "2       2     Baseline_Upsample\n",
       "3       3  Upsample_living_conf\n",
       "4       4         Upsample_conf\n",
       "5       5       Upsample_bridge"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
